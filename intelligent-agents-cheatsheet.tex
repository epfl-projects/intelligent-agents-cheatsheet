\documentclass[10pt,a4paper,landscape]{article}
\usepackage{multicol}
\usepackage{calc}
\usepackage{ifthen}
\usepackage[landscape]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,mathtools}
\usepackage{color,graphicx}
\usepackage[dvipsnames]{xcolor}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{underscore}
\usepackage{todonotes}

% Cheatsheet style
\input{style.tex}

% Shorthands
\renewcommand{\bf}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\balpha}{\boldsymbol\alpha}
\newcommand{\bbeta}{\boldsymbol\beta}
\newcommand{\bdelta}{\boldsymbol\delta}
\newcommand{\btheta}{\boldsymbol\theta}
\newcommand{\bPhi}{\boldsymbol\Phi}
\newcommand{\concept}[1]{\textcolor{Emerald}{#1}} % SeaGreen, SkyBlue, Emerald, Cerulean, CadetBlue
\newcommand{\subconcept}[1]{\textcolor{CadetBlue}{\textit{#1}}}

% Allows to easily edit out parts that are dispensible
% TODO: compilation option (long / short version)
% \def \longversion{}
\newcommand{\opt}[1]{#1}
% Modifications in order to maximize information density
\ifdefined \longversion % Nothing
\else
  % Hide optional content
  \renewcommand{\opt}[1]{}
  % Make titles smaller
  \renewcommand{\section}[1]{
    \vspace{-0.3cm}
    \begin{center}
      \color{Bittersweet}
      \hrulefill{\small~~#1~~}\hrulefill
    \end{center}
    \vspace{-0.3cm}
  }
  \renewcommand{\subsection}[1]{\section{#1}}
\fi

\pdfinfo{
  /Title (Intelligent Agents Cheatsheet)
  /Creator (Merlin Nimier-David)
  /Author (Merlin Nimier-David)
  /Subject (Intelligent Agents cheatsheet)
  /Keywords (agent, artififical intelligence, planning, auctions, game theory)
}

% -----------------------------------------------------------------------

\begin{document}
\title{Intelligent Agents Cheatsheet}

\raggedright
\footnotesize
\sffamily
\begin{multicols*}{4}

% multicol parameters
% These lengths are set only within the two main columns
%\setlength{\columnseprule}{0.25pt}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}

\opt {
  \begin{center}
  \Large{Intelligent Agents Cheatsheet}
  \end{center}
}

% ----------
\section{Reactive agents}

\concept{Reactive policy} (strategy): simple state $\rightarrow$ response mapping (may be \subconcept{stateful}). Good for realtime.
\concept{Subsumption architecture} manages conflicting behaviors.
Strategy is computed from the \concept{reward} and \concept{transition} functions to maximize immediate \textit{and} future rewards.
\concept{Decision process}: describes knowledge of rewards \& transitions. \subconcept{Markov}: nondeterministic transitions; \subconcept{partially observable MDP}: state is uncertain; \subconcept{Q-learning}: transitions and rewards are not known.
\concept{Value} of a state: $V(s_i) = R(s_i, a^*) + \gamma V(T(s_i, a^*))$, $a^*$ the best action, $\gamma$ the \subconcept{discount factor}.
The \subconcept{value iteration} algorithm (initialize $V_i$ at random, pick best action by trying all, update $V_i$, stop when max update is small) converges to the true value. For MDP, transition function is a probability distribution: take expected value.
The \subconcept{policy iteration} optimizes over the policy directly by solving for the linear equations of values for the current policy.
\concept{Q-learning}: need to learn transitions and rewards (exploration / exploitation, use $\alpha(t)$).
\concept{POMDP} can be converted to deterministic \subconcept{MDP} by replacing state by a \subconcept{belief} function.

% ----------
\section{Deliberative agents}

\concept{Deliberative architecture}: explicit representation of goal states and plans. Considers only the subset of states that may be visited.
\concept{Search algorithms}: DFS (too much time spent in unpromising branches), BFS (too much memory usage), Iterative Deepening (DFS + depth limit), Branch and Bound (ignore nodes with higher cost than best found so far). With adversary: minimax, $\alpha-\beta$ pruning.
\concept{Regret}: difference in outcome between playing move $i$ and the optimal move. In games with chance, minimize expected regret or worst-case regret.
Big / chance games: evaluate horizon states with a \subconcept{heuristic} and / or \subconcept{Monte-Carlo sampling}.
\concept{Upper Confidence Bound} for game trees: minimax over $UCB_i = \frac{\text{wins}_i}{N_i} + c \sqrt{\frac{\log{N}}{N_i}}$ ($c$: exploration parameter).

\concept{Factored representation}: circumvent state space explosion by modeling state features as predicates. Use \subconcept{situation calculus}: operators transform predicates (preconditions, add-list, delete-list). \subconcept{Frame axioms} carry over predicates that were not modified.
\subconcept{Policy} and \subconcept{reward functions} should be factored. More difficult: factoring the estimate \subconcept{value} of a state (use basis functions).
\concept{Leat-commitment principle}: delay commitment to the order in which actions are taken (modulo dependencies). Determine policy by fixpoint iteration (basis functions: solve for weights that minimize the error of the value function recurrence $\equiv$ least squares).
\concept{Partial-order planning}: discover which actions can be carried out in parallel.
\subconcept{GraphPlan} builds layers (time) with nodes (proposition and actions) and directed edges (in: preconditions, out: add-list). Built in polynomial time, not exhaustive but complete.
\concept{SAT}: goal state search can be encoded as a CSP. State $=$ vector of state variables (each with a domain), add constraints for: pre and post-conditions for operators, incompatible propositions, exclusion for operators using the same resource. Time is broken up into $2n$ discreet points (states, actions).

% ----------
\section{Multiagent systems}

\concept{Multiagent modalities}: centralized with shared memory, centralized or distributed with message passing, decentralized (no communication, but observe common signals).
\concept{Ontologies}: provides a shared vocabulary for heterogeneous agents.
\concept{Self-interested} agents: always act to maximize their own interest. We need to create incentives.
\concept{Centralized planning}: can explicitly detect conflicts and synergy. E.g. \subconcept{blackboard system} (shared memory), \subconcept{publish-subscribe system} (notify on resource usage).
Using reactive agents: optimize sum of rewards or each agent optimizes its own (find a NE using policy iteration, but probably not the best one).
Using deliberative agents: find conflicting resource usages and similar goals.
\concept{Partial-global planning}: goal tree in which each agent inserts its partial plans (expressed with predicates). Can then reorder actions, exchange tasks.
\concept{Distributed SAT}: variables (goals), values (actions carried out by agents), constraints (preconditions and resources).
\concept{Contract net}: cooperation protocol. Managers divide tasks, contractors place bids, contract is made for lowest bid (no negotiation). Tasks can be subcontracted. Market-based variation: managers increase prices until they obtain a solution.

\subsection{Distributed multiagent systems}

TODO: social laws, marginal cost, planning as SAT (i.e. Constraint Satisfaction Problem), centralized / async backtracking, dynamic programming, distributed local search, breakout algorithm

% ----------
\section{Game theory}

\concept{Games}: zero / general sum, 2 / $N$ players.
\concept{Strategies}: strictly / (very) weakly dominant, pure, mixed, \subconcept{minimax} (for zero-sum: \subconcept{value} of the game $=$ expected gain $v_A$ $=$ expected loss $v_B$). Computing minimax for B: find set of $p_i^B$ such that expected gain $v$ of A is minimized and $\forall a_i^A, \sum_{a_j^B} p_j^B R_A(a_i^A, a_j^B) \leq v$.
\concept{Utility function}: can encode risk-profile.
\concept{Support}: set of actions with $p_a > 0$.
\concept{Nash equilibria}: no player gains from changing strategy, all other things being equal. Theorem: every game has at least a set of (mixed) NE. Compute them by removing dominated actions and going through possible subsets of actions (\subconcept{supports}). For $N$ players, NE exists but not necessarily unique or minimax.
\concept{Uncertain utilities}: \subconcept{ex-ante} (no knowledge at all), \subconcept{ex-interim} (own agent type is known), \subconcept{ex-post} (strongest, knowledge of all types).
\concept{Bayes-NE}: NE over ex-ante expected utilities.
\concept{Ex-post NE}: strategies give highest utility no matter the value of the unknown information (not always possible).

\subsection{Agent cooperation, negotiation}

\concept{Correlated equilibrium}: act depending on an external factor (e.g. coin flip).
\concept{Mediator}: vehicle to enforce a contract. Plays depending on the number of agents which chose the mediator.
\concept{Negotiation}: make, accept or refuse offers to agree on a joint strategy. \subconcept{Strategic} or \subconcept{axiomatic}.
\concept{Alternating offers}: broken, first offer has more power. Can introduce time constraints, discount factor.
\concept{Nash bargaining solution}: maximize the product of utility gains (from \subconcept{conflict deal}), concession is made by deal with lowest product. Mixed strategies: can bargain about probabilities.
\concept{Monotonic concessions}: reaches NBS. Agent with lowest risk tolerance $\frac{u_i(D_i) - u_i(D_j)}{u_i(D_i) - u_i(D_c)}$ must make an offer.

\concept{Stackelberg games}: decisions in sequence between a leader and a follower.

\subsection{Mechanism design}

\concept{Social choice}: constructing a joint preference order reflecting individual, private orderings. Implementations: dominant equilibrium, Bayes-Nash equilibrium.
\concept{Mechanisms}: social choice function $+$ payment rule. Goal: \subconcept{incentive compatibility} (best strategy for agents leads to optimizing the social choice function).
\concept{Revelation principle}: for any mechanism, there is a truthful mechanism with the same outcomes and payments (proof by construction).
\concept{VCG tax}: maximizes the sum of declared valuations. $\text{tax}(A_i) = \sum_{A_{j \neq i}} v_j(d_{-i}) - v_j(d_{\text{all}})$. It is truthful, rational and incentive compatible. Generalization: \subconcept{Groves mechanism} $\approx$ VCG with offset (e.g. refund part of the tax). Problems: collusions, not Pareto-efficient (tax must be wasted).
\concept{Roberts' theorem}: affine maximizer social choice functions are the only ones that can be implemented for unrestricted preference profiles with incentive compatibility.
\concept{Median rule}: IC for single-peaked preferences.

\subsection{Auctions}

\concept{Auctions}: social choice, goals are \subconcept{optimal allocation}, \subconcept{individual rationality}.
\concept{Values}: \subconcept{private}, \subconcept{common} (entirely dependent on other's value), \subconcept{correlated}.
\concept{Auction protocols}: open-cry (\subconcept{Dutch}, \subconcept{English}); sealed-bids (\subconcept{Discriminatory}, \subconcept{Vickrey}). Problems: \subconcept{manipulability} (collusion, demand reduction lie), \subconcept{risk-averse} or non-truthful / irrational bidding, \subconcept{timing}, \subconcept{side-constraints} (e.g. procurement), authenticity, privacy.
\concept{Revenue equivalence theorem}: all 4 settings yield equivalent revenue, but not optimal allocation (not true for \subconcept{correlated values}).

\concept{Multi-unit Vickrey}: each agent pays the price of the bid it displaced from the set of winning bids.
\concept{Double auctions}: sort buy \& sell bids in opposing orders, price is last match. $M^{th}$ highest price is incentive-compatible for sellers, $(M+1)^{st}$ for the buyers. \subconcept{McAffee}: price is average of last (sell, buy) bid, but block that one $\implies$ loss of 1 trade but gain incentive compatibility. May bid with \subconcept{price-quantity graphs} (then, sum up curves and match demand).
\concept{Bargaining}: for 1 buyer and 1 seller, NE at price $0.5 \times (b_1 + b_2)$.
\concept{Independent English Auctions} ($k$ run in parallel): bidding strategies include \subconcept{straightfoward} (ignore complementarities, bid only for the best combination); \subconcept{sunk-aware} (discout perceved price of won items by some factor since they cannot be returned); \subconcept{price prediction}.
\concept{GVA auction} ($\approx$ VCG tax): pay for the difference between the best allocations without and with your bid.
\concept{GSP auction} (internet ads): $i^{th}$ highest bidder pays $(i+1)^{st}$ price to get $i^{th}$ slot (not incentive compatible, but stable prices and high revenue).

\subsection{Coalitions}

\concept{Coalitions}: when \subconcept{side-contracts} (utility redistribution) are allowed, coalition utility $geq$ others $\implies$ stable.
\concept{Core} of a game: set of payoff distributions for which the grand coalition is stable (often empty).
Core is known to be nonempty for \subconcept{Superadditive} and \subconcept{Convex} games ($v(S \cup T) \geq v(S) + v(T) - v(S \cap T)$).
\concept{Shapley value}: unique vector (if core is nonempty, SV payoffs is in it). $SV(a_i) = $ average value of added payoff when added that agent to a sub-coalition (over all orders). Agents not in any carrier coalitions has $SV(a_i) = 0$.
\concept{Weighted graph games}: agents are nodes, self-edges are payoffs, edges are payoffs for 2-coalitions (not possible for all games). Value of a coalition is the sum of edge weights in the subgraph.

\subsection{Voting protocols}

\concept{Manipulability}: non-truthful voting; removing a candidate can reverse the order; vote organizer can determine the winner by changing the order in which alternatives are presented.
\concept{Condorcet winner}: alternative that beats (or ties) all others in a pairwise majority vote (doesn't always exist; in a majority graph, it is the node with only outgoing edges).
\concept{Plurality voting}: vote for your single preferred alternative (variant: carry out $n - 1$ rounds, eliminate the least preferred at each round).
\concept{Borda count}: give $(n - 1) \dots 0$ points to alternatives.
\concept{Slater ranking}: vote between every pair of alternatives, pick the smallest transformation to obtain a majority graph.
\concept{Gibbard-Satterthwaite theorem}: any deterministic voting protocol ($\geq 3$ alternatives) has one of these properties: dictatorial, non-truthful, or some candidate cannot win.

% ---------- Page break
\newpage

% ---------- Other topics

% \section{Applications}
% \subsection{Agent-oriented software engineering}
% \subsection{Other gent applications}

% ---------- Credits
\section{Credits}
Most content taken from the lecture notes of Boi Falting's \href{http://edu.epfl.ch/coursebook/en/intelligent-agents-CS-430}{Intelligent Agents class} at EPFL, 2015.

% ---------- Footer
\vspace{0.5cm}
\hrule
\vspace{0.5cm}
\tiny
Rendered \today. Written by Merlin Nimier-David.
This work is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License.
To view a copy of this license, visit \href{http://creativecommons.org/licenses/by-sa/3.0/}{http://creativecommons.org/licenses/by-sa/3.0/} or
send a letter to Creative Commons, 444 Castro Street, Suite 900, Mountain View, California, 94041, USA.
\end{multicols*}
\end{document}
